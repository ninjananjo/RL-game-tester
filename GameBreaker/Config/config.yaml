behaviors:
    GameBreaker:
        trainer_type: ppo
        hyperparameters:
            batch_size: 128
            buffer_size: 4096
            learning_rate: 0.0003
            beta: 0.01
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 8
            learning_rate_schedule: linear
        network_settings:
            normalize: false
            hidden_units: 512
            num_layers: 2
            vis_encode_type: simple
        reward_signals:
            extrinsic:
                gamma: 0.99
                strength: 1.0
            curiosity:
                gamma: 0.99
                strength: 0.02
                encoding_size: 256
        keep_checkpoints: 5
        max_steps: 500000
        time_horizon: 128
        summary_freq: 2000
        threaded: true

    GameBreakerRND:
        trainer_type: ppo
        hyperparameters:
            batch_size: 128
            buffer_size: 4096
            learning_rate: 0.0003
            beta: 0.01
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 8
            learning_rate_schedule: linear
        network_settings:
            normalize: false
            hidden_units: 512
            num_layers: 2
            vis_encode_type: simple
        reward_signals:
            extrinsic:
                gamma: 0.99
                strength: 1.0
            rnd:
                gamma: 0.99
                strength: 0.02
                encoding_size: 256
        keep_checkpoints: 5
        max_steps: 500000
        time_horizon: 128
        summary_freq: 2000
        threaded: true

    Random:
        trainer_type: ppo
        hyperparameters:
            epsilon: 1
            epsilon_schedule: constant
        reward_signals:
            extrinsic:
                gamma: 0.99
                strength: 1.0
        keep_checkpoints: 5
        max_steps: 500000
        summary_freq: 2000
        threaded: true
